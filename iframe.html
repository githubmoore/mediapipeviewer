<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face Landmark Detection</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      overflow: hidden;
      background-color: #000;
    }
    .container {
      position: relative;
      width: 100%;
      height: 100%;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    video {
      position: absolute;
      width: 100%;
      height: 100%;
      object-fit: contain;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: contain;
    }
    .loading {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      display: flex;
      justify-content: center;
      align-items: center;
      background-color: rgba(0, 0, 0, 0.5);
    }
    .spinner {
      border: 3px solid rgba(255, 255, 255, 0.3);
      border-radius: 50%;
      border-top: 3px solid #fff;
      width: 30px;
      height: 30px;
      animation: spin 1s linear infinite;
    }
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
  </style>
</head>
<body>
  <div class="container">
    <video id="webcam" autoplay playsinline muted></video>
    <canvas id="output"></canvas>
    <div id="loading-overlay" class="loading">
      <div class="spinner"></div>
    </div>
  </div>

  <script type="module">
    import { FaceLandmarker, FilesetResolver } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10/+esm';

    // DOM elements
    const video = document.getElementById('webcam');
    const canvas = document.getElementById('output');
    const ctx = canvas.getContext('2d');
    const loadingOverlay = document.getElementById('loading-overlay');

    // State variables
    let faceLandmarker;
    let lastVideoTime = -1;
    let results = undefined;
    let rafId;

    // Initialize the app and start webcam automatically
    async function init() {
      try {
        // Create a FaceLandmarker instance
        const vision = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm'
        );
        
        faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
            delegate: 'GPU'
          },
          runningMode: 'VIDEO',
          numFaces: 1,
          minFaceDetectionConfidence: 0.5,
          minFacePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5
        });
        
        // Start the webcam automatically
        startWebcam();
      } catch (error) {
        console.error('Error initializing FaceLandmarker:', error);
      }
    }

    // Start webcam and detection
    async function startWebcam() {
      try {
        // Request camera access
        const constraints = {
          video: {
            width: { ideal: 1280 },
            height: { ideal: 720 },
            facingMode: 'user'
          }
        };
        
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        
        // Wait for video to be ready
        await new Promise(resolve => {
          video.onloadedmetadata = () => {
            resolve();
          };
        });
        
        // Set canvas dimensions to match video exactly
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        
        // Ensure the canvas position aligns perfectly with video
        function updateCanvasPosition() {
          const videoRect = video.getBoundingClientRect();
          canvas.style.position = 'absolute';
          canvas.style.top = `${videoRect.top}px`;
          canvas.style.left = `${videoRect.left}px`;
          canvas.style.width = `${videoRect.width}px`;
          canvas.style.height = `${videoRect.height}px`;
        }
        
        // Initial position update
        updateCanvasPosition();
        // Add observer to handle size changes
        const resizeObserver = new ResizeObserver(updateCanvasPosition);
        resizeObserver.observe(video);
        
        // Hide loading overlay when everything is ready
        loadingOverlay.style.display = 'none';
        
        // Start detection loop
        predictWebcam();
      } catch (error) {
        console.error('Error accessing webcam:', error);
      }
    }

    // Main detection loop
    function predictWebcam() {
      // Only run detection when video is playing
      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;
        results = faceLandmarker.detectForVideo(video, performance.now());
      }
      
      // Draw results
      if (results && results.faceLandmarks) {
        // Clear canvas
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        // Draw landmarks for each detected face
        for (const landmarks of results.faceLandmarks) {
          drawLandmarks(landmarks);
        }
      }
      
      // Continue detection loop
      rafId = requestAnimationFrame(predictWebcam);
    }

    // Draw facial landmarks on canvas - only lips
    function drawLandmarks(landmarks) {
      // Lips outline - outer lip
      const outerLipIndices = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 409, 270, 269, 267, 0, 37, 39, 40, 185];
      drawConnections(landmarks, outerLipIndices, 'rgba(255, 0, 0, 0.8)');
      
      // Inner lip
      const innerLipIndices = [78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308, 415, 310, 311, 312, 13, 82, 81, 80, 191];
      drawConnections(landmarks, innerLipIndices, 'rgba(255, 0, 0, 0.8)');
      
      // Optional: highlight key points on lips
      for (const idx of [...outerLipIndices, ...innerLipIndices]) {
        const landmark = landmarks[idx];
        const x = landmark.x * canvas.width;
        const y = landmark.y * canvas.height;
        
        ctx.beginPath();
        ctx.arc(x, y, 1, 0, 2 * Math.PI);
        ctx.fillStyle = 'rgba(255, 255, 255, 0.5)';
        ctx.fill();
      }
    }

    // Helper to draw connections between landmarks
    function drawConnections(landmarks, indices, color) {
      ctx.beginPath();
      ctx.moveTo(landmarks[indices[0]].x * canvas.width, landmarks[indices[0]].y * canvas.height);
      
      for (let i = 1; i < indices.length; i++) {
        const idx = indices[i];
        ctx.lineTo(landmarks[idx].x * canvas.width, landmarks[idx].y * canvas.height);
      }
      
      ctx.closePath();
      ctx.strokeStyle = color;
      ctx.lineWidth = 2; // Thicker line for better visibility
      ctx.stroke();
      
      // Optional: Fill with semi-transparent color
      ctx.fillStyle = 'rgba(255, 0, 0, 0.1)';
      ctx.fill();
    }

    // Handle window resize
    window.addEventListener('resize', () => {
      if (video.videoWidth) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        
        // Update canvas position on resize
        if (typeof updateCanvasPosition === 'function') {
          updateCanvasPosition();
        }
      }
    });

    // Initialize the app
    init();
  </script>
</body>
</html>